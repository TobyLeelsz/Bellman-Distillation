# Official Code Implementation of AAAI 2026 Paper: Language Model Distillation: A Temporal Difference Imitation Learning Perspective 
[Paper](https://arxiv.org/abs/2505.20335)

[Zishun Yu](https://zishun.me/)†, [Shangzhe Li](https://tobyleelsz.github.io/)†, [Xinhua Zhang](https://www.cs.uic.edu/~zhangx/)

†: Equal Contributions

## Overview
This repository explores the connection between language model distillation and imitation learning in large discrete action spaces. Prior imitation learning methods often struggle in such settings due to the lack of strong action-space priors, whereas distillation naturally benefits from guidance provided by a teacher policy. This perspective motivates our top-p Temporal Difference (top-p TD) learning approach.
We propose a plug-and-play top-p TD framework that focuses learning on high-probability tokens only. When integrated with Inverse soft-Q Learning (IQL), this approach yields consistent empirical improvements, demonstrating its effectiveness and flexibility.

## Environment Setup 
Run the following code to install the environment:
```
bash init.sh
```
Make sure that the version of the transformers package is 4.47.xx.

## Checkpoint Downloading
Please download the teacher checkpoint from [this url](https://huggingface.co/DVA13304/Qwen-2.5-3B-Teacher) and the student checkpoint from [this url](https://huggingface.co/DVA13304/Qwen-2.5-0.5B-Base). The teacher model is a finetuned version of Qwen-2.5 3B using [databricks-dolly-15K](https://github.com/databrickslabs/dolly/tree/master), while the student model is a finetuned version of Qwen-2.5 0.5B using the same dataset.

## Data Preparation
1. Download the pretraining dataset $\mathcal{D}^{PT}$ in [this url](https://huggingface.co/datasets/MiniLLM/openwebtext-processed), which is a processed version of Openwebtext dataset.
2. Download the teacher dataset from [this url](https://huggingface.co/datasets/DVA13304/Qwen-2.5-3B-Bellman), which is a dataset consisting of responses generated by the teacher model using [databricks-dolly-15K](https://github.com/databrickslabs/dolly/tree/master) prompts.

## Training
1. Modify *scripts/train_0.5B_3B.sh* with correct paths of teacher/student checkpoints and datasets.
2. Run the following command:
```
bash scripts/train_0.5B_3B.sh
```
## Evaluation
1. Select the checkpoint with highest validation Rouge-L score during training.
2. Modify the path to the evaluation checkpoint in *scripts/eval/run_eval.sh* and run:
```
bash scripts/eval/run_eval.sh
```
## Citation
If you find our work helpful to your research, please consider citing our paper as follows:
```
@article{Yu2025LanguageMD,
  title={Language Model Distillation: A Temporal Difference Imitation Learning Perspective},
  author={Zishun Yu and Shangzhe Li and Xinhua Zhang},
  journal={ArXiv},
  year={2025},
  volume={abs/2505.20335},
}
```
